# FCViT
* 비전 트랜스포머 기반 좌표 예측을 통한 직소 퍼즐 풀이
* ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
<br>
 
## 목차
### 👨‍🏫 개요
### ✅ 문제 정의
### 💡 가설 설정
### 🔬 실험 및 검증
### 📊 결론
<br>


## 👨‍🏫 개요
* __개요__: 
  * 직소퍼즐은 작은 조각을 재조립하여 완전한 이미지를 만드는 작업으로, 패턴 인식과 공간 추론과 같은 인지 능력이 필요합니다. 직소퍼즐을 직소퍼즐을 푸는 것은 인간에게는 간단해 보일 수 있지만, 컴퓨터 비전 모델에게는 복잡한 도전과제 입니다. 놀랍게도, 조각의 수가 9개로 구성된 쉬운 퍼즐 조차 컴퓨터 비전 모델에게 어려움을 주는 것이 현재 수준 입니다. 
  * 우리는 이러한 문제를 2가지 아이디어를 적용하여 해결하고자 합니다. 첫번째로 대부분의 기존 모델이 분류 알고리즘을 사용하는데, 이를 회귀 알고리즘으로 변경하고자 합니다. 두번째로 CNN 대신에 ViT (Vision Transformer)를 인코더로 활용하여 문제를 해결하고자 합니다.
* __기간__: 2023.02.01 ~ 2024.12.31
* __수행 역할__: 
  * 분류 알고리즘에서 발생하는 문제점을 회귀 알고리즘으로 해결
  * 딥러닝 모델 ViT (Vision Transformer) 아키텍처 수정
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
  * 관련 논문의 모델들을 PyTorch로 다시 구현
  * 학습 내용과 학습 과정 시각화
* __배운 점__: 
  * 딥러닝 모델의 속도와 성능 문제를 창의적 사고로 해결
  * 논문을 읽고 이해하는 능력과 코드로 구현하는 능력 향상
  * 대용량 데이터셋 (ImageNet) 사용 방법 숙지
  * 리눅스 서버 GPU 환경 모델 학습 방법 숙지
  * Python 프로그래밍 숙련도 향상
<br>



## ✅ 문제 정의
![직소퍼즐 학습](https://github.com/user-attachments/assets/302663fc-07b0-438e-acb8-8791b5e00455)
* __직소퍼즐 학습이란?__
  * 직소퍼즐 학습은 무작위로 섞인 퍼즐 조각들을 재조립하는 것입니다.
  * 이 학습은 컴퓨터 비전 분야에서 까다로운 과제이며, 패턴 인식과 공간 추론이 필요합니다.
* __왜 직소퍼즐 학습의 문제를 해결해야 하는가?__
  * 직소퍼즐을 학습한 딥러닝 모델은 `패턴 인식과 공간 추론 능력` 이 뛰어납니다.
  * 직소퍼즐을 사전 학습한 모델은 다양한 분야에서 활용할 수 있는데, 대표적으로 `객체 인식`이 있습니다.
  * 객체 인식은 대표적으로 `자율 주행`과 같은 기술에서 활용합니다.
  * 직소퍼즐은 `자기지도학습` 입니다.
  * 사람의 라벨링 없이 오직 이미지만 있어도 학습이 가능합니다.
  * Vision 분야의 오랜 숙제인 `대용량 사전학습`의 방법 중에 하나로 사용할 수 있습니다.
* __어떻게 해결할 것인가?__
  * 방법: JigsawCFN 모델의 아키텍처를 수정합니다.
  * JigsawCFN은 transfer learning을 염두한 end-to-end 모델이기 때문에 선정했습니다.
<br>



## 💡 가설 설정
* __분류 알고리즘__
  * ![분류 회귀](https://github.com/user-attachments/assets/5aa8f5bf-67ae-4c64-86a0-53fbff89cc5a)
  * 대부분의 기존 모델들은 `분류 알고리즘`을 사용해서 학습전략을 설계했습니다.
  * 직소퍼즐은 퍼즐조각의 숫자가 증가함에 따라 `순열`이 `기하급수적`으로 증가합니다.
  * (ex. 4개 퍼즐조각은 4! (24개), 9개 퍼즐 조각은 9! (362,880개)의 가능한 순열)
  * 따라서, 모델이 계산해야할 확률(=모델 사이즈)도 기하급수적으로 증가합니다.
  * `분류 알고리즘`은 직소퍼즐 학습의 효율성과 확장성에 문제를 야기하고 있습니다.
* __(가설1 설정) 회귀 알고리즘으로 변경하면 효율성과 확장성 문제를 해결할 수 있다.__
  * `회귀 알고리즘`을 사용한 우리 모델은 퍼즐조각 수평, 수직 좌표 값 (h, v)를 직접 예측합니다.
  * `퍼즐조각의 좌표`는 퍼즐조각의 숫자가 증가함에 따라 `비례`하여 증가합니다.
  * (ex. 4개의 퍼즐 조각은 4x2 (8개), 9개 퍼즐 조각은 9x2 (18개)의 좌표만 예측)
  * 따라서, 모델이 계산해야할 좌표(=모델 사이즈)는 선형적으로 증가합니다.
  * `회귀 알고리즘` 모델은 상대적으로 크기가 작고 `효율적`이며, 퍼즐 조각의 수가 늘어나더라도 커버할 수 있는 `확장성`이 있습니다. 추가적으로 이 방법은 `사람의 행동패턴과 유사`한 특징이 있습니다.
* __CNN 인코더__
  * ![CNN 인코더](https://github.com/user-attachments/assets/abcc7319-ff45-4d2f-82eb-9f6483bc4417)
  * 대부분의 기존 모델들은 `CNN 인코더`를 사용합니다.
  * 많은 상황에서 CNN은 최신 모델인 ViT에 비하여 낮은 성능을 기록합니다.
  * 모델의 성능 측면에서 CNN을 최신 아키텍처로 변경할 필요가 있습니다.
* __(가설2 설정) ViT 인코더로 대체하면 더 좋은 성능을 얻을 수 있다.__
  * `ViT 인코더`를 사용하면 더 높은 성능을 기대할 수 있습니다.
  * backbone을 쉽게 교체할 수 있도록 설계하여 개발 용이성을 확보 합니다.
<br>



## 🔬 실험 및 검증
* __FCViT 아키텍처__
  * ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
  * 회귀 알고리즘과 ViT 인코더를 적용한 직소 퍼즐 모델 아키텍처 설계
    * Input: 224x224 사이즈의 퍼즐 문제 (섞인 이미지)
    * Encoder: ViT-16/B
    * Predictor: 3개의 MLP, dim=1000, ReLU 사용
    * Output: 9개의 예측된 수평 수직 좌표 (h, v)
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
    * 인풋 이미지를 9개의 퍼즐 조각으로 자릅니다.
    * 각 퍼즐 조각에 고유 수평 수직 좌표 (h, v)를 부여합니다.
    * 고유 좌표 9개를 무작위로 섞습니다.
    * (이때 섞은 좌표가 학습의 정답인 label이 됩니다.)
    * 섞인 좌표를 기준으로 퍼즐 조각을 섞습니다.
    * (이 섞인 이미지가 모델에 입력 됩니다.)
* __데이터셋__
  * 학습 및 평가: ImageNet, JPwLEG
  * 평가: CIFAR10, iNaturalists19, MET
* __실험1: ImageNet 데이터셋 학습 및 평가__
  * ![table 1](https://github.com/user-attachments/assets/66ab979a-f70b-49d2-9737-1b25c7d5819c)
  * 기존의 모든 모델들 보다 FCViT가 더 높은 정확도를 얻었습니다.
* __실험2: JPwLEG 데이터셋 학습 및 평가__
  * ![table 2](https://github.com/user-attachments/assets/f614a105-fc46-4520-be41-365de9fc4c69)
  * JPwLEG 데이터셋도 FCViT가 더 높은 정확도를 얻었습니다.
* __실험3: 일반화 평가__
  * ![table 3](https://github.com/user-attachments/assets/83b24f71-4afd-458e-b91b-551aa35bc6e3)
  * 오직 ImageNet 데이터셋만 학습하고 다른 데이터셋에 대하여 평가 합니다.
  * 이 평가는 모델이 robustness한 특징을 추출할 수 있는지 평가 합니다.
  * robustness란 학습한 데이터셋에 국한되지 않고 일반화된 능력을 가진다는 의미 입니다.
  * 여기에서도 기존 모델에 비해 FCViT가 더 높은 정확도를 얻었습니다.
* __실험4: 시각화를 통한 비교__
  * ![figure 4](https://github.com/user-attachments/assets/6a75774d-26e0-4e98-98aa-8b4f7d740913)
  * ImageNet 데이터셋에 대한 결과를 시각화하여 비교 합니다.
  * 기존 모델은 패턴이 복잡한 경우(거북이, 동굴)에 문제를 잘 풀지 못합니다.
  * 기존 모델은 경계선이 이어지는 경우(새)에 문제를 잘 풀지 못합니다.
  * 반면에 FCViT는 모든 경우에서 올바른 위치를 예측합니다.
* __실험5: 학습 과정 시각화__
  * ![figure 5](https://github.com/user-attachments/assets/b350bdc2-70b3-47a0-9c77-ecf0871477fe)
  * FCViT가 학습하는 동안에 예측한 좌표를 시각화한 자료 입니다.
  * 처음에는 모든 조각에 대한 예측한 좌표가 중심점으로 수렴합니다.
  * 에포크가 진행될수록 퍼즐 조각을 하나씩 옮기며 정확하게 배치합니다.
  * 기존 모델과 달리 FCViT는 퍼즐 조각을 점진적으로 학습하는 것을 알 수 있습니다.
<br>



## 📊 결론
* 
<br>
