# FCViT
* 비전 트랜스포머 기반 좌표 예측을 통한 직소 퍼즐 풀이
* ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
<br>
 
## 목차
### 👨‍🏫 개요
### ✅ 문제 정의
### 💡 가설 설정
### 🔬 실험 및 검증
### 📊 결론
<br>


## 👨‍🏫 개요
* __개요__: 
  * 직소퍼즐은 작은 조각을 재조립하여 완전한 이미지를 만드는 작업으로, 패턴 인식과 공간 추론과 같은 인지 능력이 필요합니다. 직소퍼즐을 직소퍼즐을 푸는 것은 인간에게는 간단해 보일 수 있지만, 컴퓨터 비전 모델에게는 복잡한 도전과제 입니다. 놀랍게도, 조각의 수가 9개로 구성된 쉬운 퍼즐 조차 컴퓨터 비전 모델에게 어려움을 주는 것이 현재 수준 입니다. 
  * 우리는 이러한 문제를 2가지 아이디어를 적용하여 해결하고자 합니다. 첫번째로 대부분의 기존 모델이 분류 알고리즘을 사용하는데, 이를 회귀 알고리즘으로 변경하고자 합니다. 두번째로 CNN 대신에 ViT (Vision Transformer)를 인코더로 활용하여 문제를 해결하고자 합니다.
* __기간__: 2023.02.01 ~ 2024.12.31
* __수행 역할__: 
  * 분류 알고리즘에서 발생하는 문제점을 회귀 알고리즘으로 해결
  * 딥러닝 모델 ViT (Vision Transformer) 아키텍처 수정
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
  * 관련 논문의 모델들을 PyTorch로 다시 구현
  * 학습 내용과 학습 과정 시각화
* __배운 점__: 
  * 딥러닝 모델의 속도와 성능 문제를 창의적 사고로 해결
  * 논문을 읽고 이해하는 능력과 코드로 구현하는 능력 향상
  * 대용량 데이터셋 (ImageNet) 사용 방법 숙지
  * 리눅스 서버 GPU 환경 모델 학습 방법 숙지
  * Python 프로그래밍 숙련도 향상
<br>



## ✅ 문제 정의
![직소퍼즐 학습](https://github.com/user-attachments/assets/302663fc-07b0-438e-acb8-8791b5e00455)
* __직소퍼즐 학습이란?__
  * 직소퍼즐 학습은 무작위로 섞인 퍼즐 조각들을 재조립하는 것입니다.
  * 이 학습은 컴퓨터 비전 분야에서 까다로운 과제이며, 패턴 인식과 공간 추론이 필요합니다.
* __왜 직소퍼즐 학습의 문제를 해결해야 하는가?__
  * 직소퍼즐을 학습한 딥러닝 모델은 `패턴 인식과 공간 추론 능력`이 뛰어납니다.
  * 직소퍼즐을 사전 학습한 모델은 다양한 분야에서 활용할 수 있는데, 대표적으로 `객체 인식`이 있습니다.
  * 객체 인식은 대표적으로 `자율 주행`과 같은 기술에서 활용합니다.
  * 직소퍼즐은 `자기지도학습` 입니다.
  * 사람의 라벨링 없이 오직 이미지만 있어도 학습이 가능합니다.
  * Vision 분야의 오랜 숙제인 `대용량 사전학습`의 방법 중에 하나로 사용할 수 있습니다.
* __어떻게 해결할 것인가?__
  * 방법: JigsawCFN 모델의 아키텍처를 수정합니다.
  * JigsawCFN은 transfer learning을 염두한 end-to-end 모델이기 때문에 선정했습니다.
<br>



## 💡 가설 설정
* __분류 알고리즘__
  * ![분류 회귀](https://github.com/user-attachments/assets/5aa8f5bf-67ae-4c64-86a0-53fbff89cc5a)
  * 대부분의 기존 모델들은 `분류 알고리즘`을 사용해서 학습전략을 설계했습니다.
  * `분류 알고리즘`은 모든 경우의 수에 대한 확률을 계산하고 가장 높은 확률의 경우를 선택합니다.
  * 직소퍼즐의 경우 퍼즐조각의 순서인 `순열`에 대한 확률을 계산해야 합니다.
  * 직소퍼즐은 퍼즐조각의 숫자가 증가함에 따라 `순열`이 기하급수적으로 증가합니다.
  * 예를 들어 4개 퍼즐조각은 4! (24개), 9개 퍼즐 조각은 9! (362,880개)의 가능한 순열이 있습니다.
  * 퍼즐조각의 숫자가 증가함에 따라 모델이 계산해야할 확률(=모델 사이즈)도 기하급수적으로 증가합니다.
  * `분류 알고리즘`은 직소퍼즐 학습의 효율성과 확장성에 문제를 야기하고 있습니다.
* __(가설1 설정) 회귀 알고리즘으로 변경하면 효율성과 확장성 문제를 해결할 수 있다.__
  * `회귀 알고리즘`을 사용한 우리 모델은 퍼즐조각 수평, 수직 좌표 값 (h, v)를 직접 예측합니다.
  * 퍼즐조각의 좌표는 퍼즐조각의 숫자와 비례하여 증가합니다.
  * 예를 들어 4개의 퍼즐 조각은 4x2 (8개), 9개 퍼즐 조각은 9x2 (18개)의 좌표만 예측하면 됩니다. 
  * 퍼즐조각의 숫자가 증가해도 모델이 계산해야할 좌표(=모델 사이즈)는 선형적으로 증가합니다.
  * `회귀 알고리즘` 모델은 상대적으로 크기가 작고 `효율적`이며, 퍼즐 조각의 수가 늘어나더라도 커버할 수 있는 `확장성`이 있습니다. 또한 이 방법은 `사람의 행동패턴`과 더 유사한 특징이 있습니다.
* __CNN 인코더__
  * ![CNN 인코더](https://github.com/user-attachments/assets/abcc7319-ff45-4d2f-82eb-9f6483bc4417)
  * 대부분의 기존 모델들은 `CNN 인코더`를 사용합니다.
  * 많은 상황에서 CNN은 최신 모델인 ViT에 비하여 낮은 성능을 기록합니다.
  * 모델의 성능 측면에서 CNN을 최신 아키텍처로 변경할 필요가 있습니다.
* __(가설2 설정) ViT 인코더로 대체하면 더 좋은 성능을 얻을 수 있다.__
  * `ViT 인코더`를 사용하면 더 높은 성능을 기대할 수 있습니다.
  * backbone을 쉽게 교체할 수 있도록 설계하여 개발 용이성을 확보 합니다.
<br>



## 🔬 실험 및 검증
* __FCViT 아키텍처__
  * ![fcvit 아키텍처](https://github.com/user-attachments/assets/87ac17a0-2590-4bdc-bb03-a8f1937add0c)
  * 회귀 알고리즘과 ViT 인코더를 적용한 직소 퍼즐 모델 아키텍처 설계
    * Input: 224x224 사이즈의 퍼즐 문제 (섞인 이미지)
    * Encoder: ViT-16/B
    * Predictor: 3개의 MLP, dim=1000, ReLU 사용
    * Output: 9개의 예측된 수평 수직 좌표 (h, v)
  * 자기지도학습을 위한 데이터 처리 및 학습 전략 설계
    * 인풋 이미지를 9개의 퍼즐 조각으로 자릅니다.
    * 각 퍼즐 조각에 고유 수평 수직 좌표 (h, v)를 부여합니다.
    * 고유 좌표 9개를 무작위로 섞습니다.
    * (이때 섞은 좌표가 학습의 정답인 label이 됩니다.)
    * 섞인 좌표를 기준으로 퍼즐 조각을 섞습니다.
    * (이 섞인 이미지가 모델에 입력 됩니다.)
* __데이터셋__
  * 학습 및 평가: ImageNet, JPwLEG
  * 평가: CIFAR10, iNaturalists19, MET
* __실험1: ImageNet 데이터셋 학습 및 평가__
  * ![table 1](https://github.com/user-attachments/assets/66ab979a-f70b-49d2-9737-1b25c7d5819c)
  * 기존의 모든 모델들 보다 FCViT가 더 높은 accuracy를 얻었습니다.
* __실험2: JPwLEG 데이터셋 학습 및 평가__
  * ![table 2](https://github.com/user-attachments/assets/f614a105-fc46-4520-be41-365de9fc4c69)
  * 앞선 이미지넷과 동일하게 FCViT가 더 높은 accuracy를 얻었습니다.
<br>



## 📊 결론
* 
<br>
